/**
 * Compact term list: t=term, d=definition, l=level (2-5), c=category.
 * Used by constants.ts to build full Flashcard[] with generated id, example, quizTip.
 */
export const TERM_ENTRIES: { t: string; d: string; l: number; c: string }[] = [
  // Cloud & Internet Basics (Level 2)
  { t: "Cloud", d: "A metaphor for the internet or remote servers that provide on-demand computing resources.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Cloud Computing", d: "Delivery of computing services over the internet (servers, storage, databases, analytics).", l: 2, c: "Cloud & Internet Basics" },
  { t: "Server", d: "A computer or program that provides services, data, or resources to clients.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Client", d: "A device or application that requests services or data from a server.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Data Center", d: "A facility that houses servers and networking equipment for storing and processing data.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Virtual Machine (VM)", d: "An emulation of a physical computer that runs an operating system and applications.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Virtualization", d: "Creating a virtual version of hardware, storage, or network resources.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Subscription", d: "An agreement to use a service or product, often with recurring billing.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Portal", d: "A web-based entry point for accessing applications and services.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Dashboard", d: "A visual summary of key metrics and controls in one screen.", l: 2, c: "Cloud & Internet Basics" },
  { t: "URL", d: "Uniform Resource Locator; the address of a resource on the web.", l: 2, c: "Cloud & Internet Basics" },
  { t: "HTTP", d: "HyperText Transfer Protocol; unencrypted protocol for transferring web data.", l: 2, c: "Cloud & Internet Basics" },
  { t: "HTTPS", d: "HTTP Secure; encrypted version of HTTP using TLS/SSL.", l: 2, c: "Cloud & Internet Basics" },
  { t: "API", d: "Application Programming Interface; a set of rules for software to communicate.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Endpoint", d: "A URL or address where an API or service can be accessed.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Request", d: "A message sent by a client to a server asking for data or an action.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Response", d: "The data or status returned by a server to a client request.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Status Code", d: "A numeric code in an HTTP response (e.g. 200 OK, 404 Not Found).", l: 2, c: "Cloud & Internet Basics" },
  { t: "GET", d: "HTTP method used to retrieve data from a resource.", l: 2, c: "Cloud & Internet Basics" },
  { t: "POST", d: "HTTP method used to send data to create or update a resource.", l: 2, c: "Cloud & Internet Basics" },
  { t: "PUT", d: "HTTP method used to replace or update a resource at a given URL.", l: 2, c: "Cloud & Internet Basics" },
  { t: "DELETE", d: "HTTP method used to remove a resource.", l: 2, c: "Cloud & Internet Basics" },
  { t: "IP Address", d: "A unique numeric label assigned to a device on a network.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Domain", d: "A human-readable name that maps to an IP address (e.g. microsoft.com).", l: 2, c: "Cloud & Internet Basics" },
  { t: "DNS", d: "Domain Name System; translates domain names to IP addresses.", l: 2, c: "Cloud & Internet Basics" },
  { t: "Firewall", d: "Security system that controls incoming and outgoing network traffic.", l: 2, c: "Cloud & Internet Basics" },
  { t: "VPN", d: "Virtual Private Network; encrypted connection over a public network.", l: 2, c: "Cloud & Internet Basics" },
  // Azure Basics (Level 2)
  { t: "Microsoft Azure", d: "Microsoft's cloud computing platform for building, deploying, and managing applications.", l: 2, c: "Azure Basics" },
  { t: "Azure Portal", d: "Web-based console at portal.azure.com for managing Azure resources.", l: 2, c: "Azure Basics" },
  { t: "Resource Group", d: "A container in Azure that holds related resources for a solution.", l: 2, c: "Azure Basics" },
  { t: "Subscription", d: "In Azure, a logical unit that groups resources and defines billing boundaries.", l: 2, c: "Azure Basics" },
  { t: "Region", d: "A geographic location where Azure datacenters are located.", l: 2, c: "Azure Basics" },
  { t: "Tenant", d: "A dedicated instance of Azure AD that represents an organization.", l: 2, c: "Azure Basics" },
  { t: "Availability Zone", d: "Physically separate datacenter within a region for high availability.", l: 2, c: "Azure Basics" },
  { t: "Azure Active Directory (AAD)", d: "Microsoft's cloud-based identity and access management service.", l: 2, c: "Azure Basics" },
  { t: "Microsoft Entra ID", d: "The current name for Azure Active Directory.", l: 2, c: "Azure Basics" },
  { t: "Storage Account", d: "Azure resource that provides namespace for Blob, File, Queue, and Table storage.", l: 2, c: "Azure Basics" },
  { t: "Blob", d: "Binary Large Object; a single unit of unstructured data in blob storage.", l: 2, c: "Azure Basics" },
  { t: "Container", d: "In Azure Storage, a container groups blobs like a folder.", l: 2, c: "Azure Basics" },
  { t: "Azure Blob Storage", d: "Object storage for massive amounts of unstructured data (e.g. files, backups).", l: 2, c: "Azure Basics" },
  { t: "Azure Virtual Machine", d: "On-demand scalable compute in Azure (IaaS).", l: 2, c: "Azure Basics" },
  { t: "Azure Cost Management", d: "Tool for monitoring and optimizing Azure spending.", l: 2, c: "Azure Basics" },
  { t: "Azure Advisor", d: "Service that recommends best practices for cost, security, and reliability.", l: 2, c: "Azure Basics" },
  { t: "Azure Monitor", d: "Platform for collecting and analyzing telemetry from Azure and on-premises.", l: 2, c: "Azure Basics" },
  // Data Basics (Level 2)
  { t: "Data", d: "Facts or figures used for reference or analysis.", l: 2, c: "Data Basics" },
  { t: "Database", d: "Organized collection of structured data stored and accessed electronically.", l: 2, c: "Data Basics" },
  { t: "Table", d: "A set of rows and columns storing data in a database.", l: 2, c: "Data Basics" },
  { t: "Row", d: "A single record in a database table.", l: 2, c: "Data Basics" },
  { t: "Column", d: "A vertical set of values representing one attribute in a table.", l: 2, c: "Data Basics" },
  { t: "Record", d: "A single entry (row) in a database table.", l: 2, c: "Data Basics" },
  { t: "Field", d: "A single piece of data in a record (column value).", l: 2, c: "Data Basics" },
  { t: "Primary Key", d: "A column or set of columns that uniquely identifies each row in a table.", l: 2, c: "Data Basics" },
  { t: "Foreign Key", d: "A column that references the primary key of another table to enforce relationships.", l: 2, c: "Data Basics" },
  { t: "Index", d: "A structure that speeds up lookups on one or more columns.", l: 2, c: "Data Basics" },
  { t: "Structured Data", d: "Data organized in a fixed schema (e.g. tables, rows, columns).", l: 2, c: "Data Basics" },
  { t: "Unstructured Data", d: "Data without a predefined schema (e.g. text, images, logs).", l: 2, c: "Data Basics" },
  { t: "Semi-structured Data", d: "Data with some structure but flexible schema (e.g. JSON, XML).", l: 2, c: "Data Basics" },
  { t: "CSV", d: "Comma-separated values; a simple text format for tabular data.", l: 2, c: "Data Basics" },
  { t: "JSON", d: "JavaScript Object Notation; lightweight format for storing and exchanging data.", l: 2, c: "Data Basics" },
  { t: "XML", d: "Extensible Markup Language; format for encoding documents and data.", l: 2, c: "Data Basics" },
  { t: "TXT", d: "Plain text file with no formatting.", l: 2, c: "Data Basics" },
  { t: "XLSX", d: "Excel workbook format (open XML).", l: 2, c: "Data Basics" },
  { t: "Import", d: "Bringing data from an external source into a system.", l: 2, c: "Data Basics" },
  { t: "Export", d: "Sending data from a system to an external file or system.", l: 2, c: "Data Basics" },
  { t: "Backup", d: "A copy of data kept for recovery in case of loss.", l: 2, c: "Data Basics" },
  { t: "Restore", d: "Recovering data from a backup to its original or new location.", l: 2, c: "Data Basics" },
  // SQL Fundamentals (Level 3)
  { t: "SQL", d: "Structured Query Language; standard language for managing relational databases.", l: 3, c: "SQL Fundamentals" },
  { t: "T-SQL", d: "Transact-SQL; Microsoft's extension of SQL used in SQL Server.", l: 3, c: "SQL Fundamentals" },
  { t: "Query", d: "A request for data or an operation on data in a database.", l: 3, c: "SQL Fundamentals" },
  { t: "SELECT", d: "SQL clause used to retrieve data from one or more tables.", l: 3, c: "SQL Fundamentals" },
  { t: "FROM", d: "SQL clause that specifies the table(s) to query.", l: 3, c: "SQL Fundamentals" },
  { t: "WHERE", d: "SQL clause that filters rows based on conditions.", l: 3, c: "SQL Fundamentals" },
  { t: "ORDER BY", d: "SQL clause that sorts the result set by one or more columns.", l: 3, c: "SQL Fundamentals" },
  { t: "GROUP BY", d: "SQL clause that groups rows with the same values for aggregation.", l: 3, c: "SQL Fundamentals" },
  { t: "HAVING", d: "SQL clause that filters groups after GROUP BY (like WHERE for groups).", l: 3, c: "SQL Fundamentals" },
  { t: "DISTINCT", d: "SQL keyword that removes duplicate rows from the result.", l: 3, c: "SQL Fundamentals" },
  { t: "INSERT", d: "SQL command that adds new rows to a table.", l: 3, c: "SQL Fundamentals" },
  { t: "UPDATE", d: "SQL command that modifies existing rows in a table.", l: 3, c: "SQL Fundamentals" },
  { t: "DELETE", d: "SQL command that removes rows from a table.", l: 3, c: "SQL Fundamentals" },
  { t: "CREATE TABLE", d: "SQL command that creates a new table with a defined structure.", l: 3, c: "SQL Fundamentals" },
  { t: "DROP TABLE", d: "SQL command that removes a table and its data.", l: 3, c: "SQL Fundamentals" },
  { t: "ALTER TABLE", d: "SQL command that changes the structure of an existing table.", l: 3, c: "SQL Fundamentals" },
  { t: "TRUNCATE", d: "SQL command that removes all rows from a table without logging row deletes.", l: 3, c: "SQL Fundamentals" },
  { t: "JOIN", d: "SQL operation that combines rows from two or more tables based on a related column.", l: 3, c: "SQL Fundamentals" },
  { t: "INNER JOIN", d: "Join that returns only rows with matching values in both tables.", l: 3, c: "SQL Fundamentals" },
  { t: "LEFT JOIN", d: "Join that returns all rows from the left table and matches from the right.", l: 3, c: "SQL Fundamentals" },
  { t: "RIGHT JOIN", d: "Join that returns all rows from the right table and matches from the left.", l: 3, c: "SQL Fundamentals" },
  { t: "FULL OUTER JOIN", d: "Join that returns all rows from both tables, with NULLs where no match.", l: 3, c: "SQL Fundamentals" },
  { t: "UNION", d: "SQL operator that combines result sets of two queries and removes duplicates.", l: 3, c: "SQL Fundamentals" },
  { t: "UNION ALL", d: "SQL operator that combines result sets without removing duplicates.", l: 3, c: "SQL Fundamentals" },
  { t: "COUNT", d: "SQL aggregate function that returns the number of rows.", l: 3, c: "SQL Fundamentals" },
  { t: "SUM", d: "SQL aggregate function that returns the sum of a numeric column.", l: 3, c: "SQL Fundamentals" },
  { t: "AVG", d: "SQL aggregate function that returns the average of a numeric column.", l: 3, c: "SQL Fundamentals" },
  { t: "MIN", d: "SQL aggregate function that returns the minimum value.", l: 3, c: "SQL Fundamentals" },
  { t: "MAX", d: "SQL aggregate function that returns the maximum value.", l: 3, c: "SQL Fundamentals" },
  { t: "NULL", d: "SQL value representing missing or unknown data.", l: 3, c: "SQL Fundamentals" },
  { t: "NOT NULL", d: "Constraint that disallows NULL values in a column.", l: 3, c: "SQL Fundamentals" },
  { t: "DEFAULT", d: "Constraint or keyword that specifies a default value for a column.", l: 3, c: "SQL Fundamentals" },
  { t: "CONSTRAINT", d: "Rule that enforces data integrity (e.g. primary key, foreign key).", l: 3, c: "SQL Fundamentals" },
  { t: "VIEW", d: "Virtual table defined by a SQL query; no physical storage.", l: 3, c: "SQL Fundamentals" },
  { t: "Stored Procedure", d: "Precompiled set of SQL statements stored in the database.", l: 3, c: "SQL Fundamentals" },
  { t: "Function", d: "In SQL, a routine that returns a value and can be used in expressions.", l: 3, c: "SQL Fundamentals" },
  { t: "Trigger", d: "Database object that runs automatically when a specified event occurs.", l: 3, c: "SQL Fundamentals" },
  // Python Basics (Level 3)
  { t: "Python", d: "High-level programming language known for readability and broad use in data and automation.", l: 3, c: "Python Basics" },
  { t: "Script", d: "A file containing code that is executed (e.g. .py file).", l: 3, c: "Python Basics" },
  { t: "Variable", d: "A name that refers to a value stored in memory.", l: 3, c: "Python Basics" },
  { t: "String", d: "A sequence of characters (text) in Python.", l: 3, c: "Python Basics" },
  { t: "Integer", d: "Whole number type in Python (int).", l: 3, c: "Python Basics" },
  { t: "Float", d: "Floating-point number type in Python.", l: 3, c: "Python Basics" },
  { t: "Boolean", d: "Logical type with values True or False.", l: 3, c: "Python Basics" },
  { t: "List", d: "Ordered, mutable collection of items in Python.", l: 3, c: "Python Basics" },
  { t: "Dictionary", d: "Key-value mapping type in Python (dict).", l: 3, c: "Python Basics" },
  { t: "Tuple", d: "Ordered, immutable sequence in Python.", l: 3, c: "Python Basics" },
  { t: "Set", d: "Unordered collection of unique items in Python.", l: 3, c: "Python Basics" },
  { t: "Print", d: "Built-in function that outputs text to the console.", l: 3, c: "Python Basics" },
  { t: "Input", d: "Built-in function that reads a line of input from the user.", l: 3, c: "Python Basics" },
  { t: "Return", d: "Statement that sends a value back from a function.", l: 3, c: "Python Basics" },
  { t: "Import", d: "Statement to load a module or names from a module.", l: 3, c: "Python Basics" },
  { t: "Library", d: "Collection of reusable code (modules) for specific tasks.", l: 3, c: "Python Basics" },
  { t: "Module", d: "A Python file containing definitions and statements.", l: 3, c: "Python Basics" },
  { t: "Package", d: "A directory containing modules and optionally subpackages.", l: 3, c: "Python Basics" },
  { t: "If / Else", d: "Conditional statements for branching logic.", l: 3, c: "Python Basics" },
  { t: "For Loop", d: "Control structure that iterates over a sequence.", l: 3, c: "Python Basics" },
  { t: "While Loop", d: "Control structure that repeats while a condition is true.", l: 3, c: "Python Basics" },
  { t: "Function", d: "Reusable block of code defined with def.", l: 3, c: "Python Basics" },
  { t: "Argument", d: "Value passed to a function when it is called.", l: 3, c: "Python Basics" },
  { t: "Parameter", d: "Variable in a function definition that receives an argument.", l: 3, c: "Python Basics" },
  { t: "Try / Except", d: "Construct for catching and handling exceptions.", l: 3, c: "Python Basics" },
  { t: "Exception", d: "Error that occurs at runtime; can be caught and handled.", l: 3, c: "Python Basics" },
  { t: "Error", d: "Condition that prevents the program from running correctly.", l: 3, c: "Python Basics" },
  { t: "Comment", d: "Text in code ignored by the interpreter (e.g. # or docstring).", l: 3, c: "Python Basics" },
  { t: "Indentation", d: "Spaces or tabs used to define blocks of code in Python.", l: 3, c: "Python Basics" },
  { t: "Syntax", d: "Rules that define the structure of valid code.", l: 3, c: "Python Basics" },
  { t: "pip", d: "Package installer for Python (PyPI).", l: 3, c: "Python Basics" },
  { t: "Virtual Environment", d: "Isolated Python environment for project dependencies.", l: 3, c: "Python Basics" },
  { t: "venv", d: "Built-in module for creating virtual environments in Python.", l: 3, c: "Python Basics" },
  { t: "requirements.txt", d: "File listing Python package dependencies for pip install.", l: 3, c: "Python Basics" },
  // File Formats (Level 3)
  { t: "CSV (Comma-Separated Values)", d: "Text format for tabular data with comma-separated fields.", l: 3, c: "File Formats" },
  { t: "JSON (JavaScript Object Notation)", d: "Lightweight text format for key-value and array data.", l: 3, c: "File Formats" },
  { t: "XML (Extensible Markup Language)", d: "Markup language for encoding structured data with tags.", l: 3, c: "File Formats" },
  { t: "TXT (Text)", d: "Plain text file with no structure.", l: 3, c: "File Formats" },
  { t: "XLSX (Excel)", d: "Microsoft Excel workbook format (Office Open XML).", l: 3, c: "File Formats" },
  { t: "TSV (Tab Separated Values)", d: "Tab-delimited text format for tabular data.", l: 3, c: "File Formats" },
  { t: "NDJSON / JSONL", d: "Newline-delimited JSON; one JSON object per line.", l: 3, c: "File Formats" },
  { t: "Parquet", d: "Columnar storage format for efficient analytics.", l: 3, c: "File Formats" },
  { t: "Avro", d: "Row-based format with schema; good for streaming.", l: 3, c: "File Formats" },
  { t: "ORC", d: "Optimized Row Columnar format for Hadoop ecosystems.", l: 3, c: "File Formats" },
  { t: "Delta", d: "Storage format that adds ACID and time travel on data lakes.", l: 3, c: "File Formats" },
  { t: "GZIP", d: "Compression algorithm and file format.", l: 3, c: "File Formats" },
  { t: "Snappy", d: "Fast compression library often used with Parquet.", l: 3, c: "File Formats" },
  { t: "LZ4", d: "Very fast compression algorithm.", l: 3, c: "File Formats" },
  { t: "ZIP", d: "Archive format that compresses and bundles files.", l: 3, c: "File Formats" },
  { t: "Columnar Format", d: "Storage layout by column rather than row; good for analytics.", l: 3, c: "File Formats" },
  { t: "Row Format", d: "Storage layout by row; traditional for OLTP.", l: 3, c: "File Formats" },
  { t: "Binary Format", d: "Data stored in non-human-readable binary form.", l: 3, c: "File Formats" },
  { t: "Compression", d: "Reducing file size by encoding data more efficiently.", l: 3, c: "File Formats" },
  { t: "Serialization", d: "Converting an object or data structure into a storable/transmittable format.", l: 3, c: "File Formats" },
  { t: "Deserialization", d: "Converting serialized data back into objects or structures.", l: 3, c: "File Formats" },
  // Python Intermediate (Level 4)
  { t: "Class", d: "Blueprint for creating objects; defines attributes and methods.", l: 4, c: "Python Intermediate" },
  { t: "Object", d: "Instance of a class with its own state and behavior.", l: 4, c: "Python Intermediate" },
  { t: "Instance", d: "A concrete occurrence of a class (an object).", l: 4, c: "Python Intermediate" },
  { t: "Method", d: "Function defined inside a class and called on an instance.", l: 4, c: "Python Intermediate" },
  { t: "Attribute", d: "Variable or property belonging to a class or instance.", l: 4, c: "Python Intermediate" },
  { t: "Inheritance", d: "Mechanism where a class gets attributes and methods from a parent class.", l: 4, c: "Python Intermediate" },
  { t: "Polymorphism", d: "Ability of different types to be used through the same interface.", l: 4, c: "Python Intermediate" },
  { t: "Encapsulation", d: "Bundling data and methods that operate on it; hiding internal state.", l: 4, c: "Python Intermediate" },
  { t: "Abstraction", d: "Hiding complex implementation details and exposing a simple interface.", l: 4, c: "Python Intermediate" },
  { t: "Constructor", d: "Special method that initializes a new object (e.g. __init__).", l: 4, c: "Python Intermediate" },
  { t: "__init__", d: "Python method that initializes a new instance; the constructor.", l: 4, c: "Python Intermediate" },
  { t: "Self", d: "Convention for the first parameter of instance methods; refers to the instance.", l: 4, c: "Python Intermediate" },
  { t: "Decorator", d: "Function that modifies or wraps another function or class.", l: 4, c: "Python Intermediate" },
  { t: "Iterator", d: "Object that produces values one at a time (implements __iter__, __next__).", l: 4, c: "Python Intermediate" },
  { t: "Generator", d: "Function that yields values lazily; returns a generator iterator.", l: 4, c: "Python Intermediate" },
  { t: "Yield", d: "Keyword that pauses a function and returns a value to the caller.", l: 4, c: "Python Intermediate" },
  { t: "yield from", d: "Delegates to a sub-generator in a generator function.", l: 4, c: "Python Intermediate" },
  { t: "next()", d: "Built-in that returns the next item from an iterator.", l: 4, c: "Python Intermediate" },
  { t: "iter()", d: "Built-in that returns an iterator from an iterable.", l: 4, c: "Python Intermediate" },
  { t: "StopIteration", d: "Exception raised when an iterator has no more items.", l: 4, c: "Python Intermediate" },
  { t: "Context Manager", d: "Object that defines __enter__ and __exit__ for use with 'with'.", l: 4, c: "Python Intermediate" },
  { t: "with statement", d: "Statement that ensures setup and teardown (e.g. open file, then close).", l: 4, c: "Python Intermediate" },
  { t: "Dunder Method (Magic Method)", d: "Special method with double underscores (e.g. __len__, __str__).", l: 4, c: "Python Intermediate" },
  { t: "Lambda", d: "Anonymous function defined with the lambda keyword.", l: 4, c: "Python Intermediate" },
  { t: "List Comprehension", d: "Compact syntax to create a list from an iterable.", l: 4, c: "Python Intermediate" },
  { t: "Generator Expression", d: "Expression that returns a generator (like a list comp but lazy).", l: 4, c: "Python Intermediate" },
  { t: "*args", d: "Syntax to pass a variable number of positional arguments to a function.", l: 4, c: "Python Intermediate" },
  { t: "**kwargs", d: "Syntax to pass a variable number of keyword arguments to a function.", l: 4, c: "Python Intermediate" },
  { t: "Scope", d: "Region where a variable is visible and can be used.", l: 4, c: "Python Intermediate" },
  { t: "Closure", d: "Inner function that captures variables from the enclosing scope.", l: 4, c: "Python Intermediate" },
  { t: "First-class Function", d: "Concept that functions can be passed as arguments and returned.", l: 4, c: "Python Intermediate" },
  { t: "Higher-order Function", d: "Function that takes one or more functions as arguments or returns a function.", l: 4, c: "Python Intermediate" },
  { t: "Recursion", d: "Function that calls itself to solve a problem.", l: 4, c: "Python Intermediate" },
  { t: "Global / Local / Nonlocal", d: "Keywords that define variable scope (module, function, enclosing).", l: 4, c: "Python Intermediate" },
  { t: "Type Hinting", d: "Annotations that indicate expected types (e.g. def f(x: int) -> str).", l: 4, c: "Python Intermediate" },
  { t: "Annotation", d: "Syntax for attaching metadata to variables or return values (type hints).", l: 4, c: "Python Intermediate" },
  { t: "Optional", d: "Typing hint: value can be of type T or None.", l: 4, c: "Python Intermediate" },
  { t: "Union", d: "Typing hint: value can be one of several types.", l: 4, c: "Python Intermediate" },
  { t: "Any", d: "Typing hint that allows any type.", l: 4, c: "Python Intermediate" },
  { t: "Dataclass", d: "Decorator/class that auto-generates __init__, __repr__, etc. from fields.", l: 4, c: "Python Intermediate" },
  { t: "Namedtuple", d: "Factory for creating tuple subclasses with named fields.", l: 4, c: "Python Intermediate" },
  { t: "Enum", d: "Set of symbolic names (constants) bound to unique values.", l: 4, c: "Python Intermediate" },
  { t: "Abstract Class", d: "Class that cannot be instantiated; meant to be subclassed.", l: 4, c: "Python Intermediate" },
  { t: "@abstractmethod", d: "Decorator that marks a method as abstract (must be overridden).", l: 4, c: "Python Intermediate" },
  { t: "@staticmethod", d: "Method that belongs to the class and does not receive 'self'.", l: 4, c: "Python Intermediate" },
  { t: "@classmethod", d: "Method that receives the class as first argument (cls).", l: 4, c: "Python Intermediate" },
  { t: "@property", d: "Decorator that defines a getter (and optionally setter) for an attribute.", l: 4, c: "Python Intermediate" },
  { t: "Unpacking", d: "Spreading elements of an iterable into arguments or assignments (*, **).", l: 4, c: "Python Intermediate" },
  { t: "Threading", d: "Concurrency model using multiple threads in a single process.", l: 4, c: "Python Intermediate" },
  { t: "Multiprocessing", d: "Running multiple processes to use multiple CPU cores.", l: 4, c: "Python Intermediate" },
  { t: "Concurrency", d: "Dealing with multiple tasks in overlapping time periods.", l: 4, c: "Python Intermediate" },
  { t: "Parallelism", d: "Executing multiple tasks simultaneously (e.g. on multiple cores).", l: 4, c: "Python Intermediate" },
  { t: "async / await", d: "Syntax for writing asynchronous code (coroutines).", l: 4, c: "Python Intermediate" },
  { t: "asyncio", d: "Library for writing concurrent code using async/await.", l: 4, c: "Python Intermediate" },
  { t: "Coroutine", d: "Function defined with async def; can be paused and resumed.", l: 4, c: "Python Intermediate" },
  { t: "GIL (Global Interpreter Lock)", d: "Mutex that allows only one thread to execute Python bytecode at a time.", l: 4, c: "Python Intermediate" },
  { t: "Garbage Collection", d: "Automatic reclamation of memory for objects no longer in use.", l: 4, c: "Python Intermediate" },
  // Python Key Libraries (Level 4)
  { t: "Pandas", d: "Library for data manipulation and analysis (DataFrames, Series).", l: 4, c: "Python Key Libraries" },
  { t: "NumPy", d: "Library for numerical computing with arrays and linear algebra.", l: 4, c: "Python Key Libraries" },
  { t: "Matplotlib", d: "Library for creating static and interactive visualizations.", l: 4, c: "Python Key Libraries" },
  { t: "os", d: "Module for interacting with the operating system (paths, env, etc.).", l: 4, c: "Python Key Libraries" },
  { t: "sys", d: "Module for system-specific parameters and functions.", l: 4, c: "Python Key Libraries" },
  { t: "re (Regular Expression)", d: "Module for pattern matching and text search with regex.", l: 4, c: "Python Key Libraries" },
  { t: "json", d: "Module for encoding and decoding JSON data.", l: 4, c: "Python Key Libraries" },
  { t: "csv", d: "Module for reading and writing CSV files.", l: 4, c: "Python Key Libraries" },
  { t: "datetime", d: "Module for date and time types and operations.", l: 4, c: "Python Key Libraries" },
  { t: "timedelta", d: "Represents a duration between two dates or times.", l: 4, c: "Python Key Libraries" },
  { t: "math", d: "Module for mathematical functions.", l: 4, c: "Python Key Libraries" },
  { t: "random", d: "Module for generating pseudo-random numbers and choices.", l: 4, c: "Python Key Libraries" },
  { t: "collections", d: "Module with specialized container datatypes (defaultdict, Counter, etc.).", l: 4, c: "Python Key Libraries" },
  { t: "defaultdict", d: "Dict subclass that provides default values for missing keys.", l: 4, c: "Python Key Libraries" },
  { t: "Counter", d: "Dict subclass for counting hashable objects.", l: 4, c: "Python Key Libraries" },
  { t: "deque", d: "Double-ended queue; efficient appends and pops from both ends.", l: 4, c: "Python Key Libraries" },
  { t: "itertools", d: "Module with functions for creating iterators (combinations, permutations, etc.).", l: 4, c: "Python Key Libraries" },
  { t: "functools", d: "Module for higher-order functions (reduce, partial, lru_cache, etc.).", l: 4, c: "Python Key Libraries" },
  { t: "pathlib", d: "Module for object-oriented path handling.", l: 4, c: "Python Key Libraries" },
  { t: "shutil", d: "Module for high-level file operations (copy, move, etc.).", l: 4, c: "Python Key Libraries" },
  { t: "logging", d: "Module for flexible event logging.", l: 4, c: "Python Key Libraries" },
  { t: "traceback", d: "Module for extracting and formatting stack traces.", l: 4, c: "Python Key Libraries" },
  { t: "unittest", d: "Built-in unit testing framework.", l: 4, c: "Python Key Libraries" },
  { t: "pytest", d: "Popular testing framework for Python.", l: 4, c: "Python Key Libraries" },
  { t: "subprocess", d: "Module for spawning and managing subprocesses.", l: 4, c: "Python Key Libraries" },
  { t: "argparse", d: "Module for parsing command-line arguments.", l: 4, c: "Python Key Libraries" },
  { t: "dotenv", d: "Loads environment variables from a .env file.", l: 4, c: "Python Key Libraries" },
  { t: "typing", d: "Module for type hints and generic types.", l: 4, c: "Python Key Libraries" },
  { t: "pickle", d: "Module for serializing and deserializing Python objects.", l: 4, c: "Python Key Libraries" },
  { t: "copy", d: "Module for shallow and deep copy operations.", l: 4, c: "Python Key Libraries" },
  { t: "deepcopy", d: "Creates a deep copy of an object (recursive copy).", l: 4, c: "Python Key Libraries" },
  { t: "requests", d: "Library for making HTTP requests.", l: 4, c: "Python Key Libraries" },
  { t: "urllib", d: "Module for opening URLs and handling URLs.", l: 4, c: "Python Key Libraries" },
  { t: "sqlalchemy", d: "SQL toolkit and ORM for Python.", l: 4, c: "Python Key Libraries" },
  { t: "psycopg2", d: "PostgreSQL adapter for Python.", l: 4, c: "Python Key Libraries" },
  { t: "pymongo", d: "MongoDB driver for Python.", l: 4, c: "Python Key Libraries" },
  { t: "azure-storage-blob", d: "Azure SDK for Blob storage.", l: 4, c: "Python Key Libraries" },
  { t: "azure-identity", d: "Azure SDK for authentication (Managed Identity, etc.).", l: 4, c: "Python Key Libraries" },
  { t: "azure-keyvault-secrets", d: "Azure SDK for Key Vault secrets.", l: 4, c: "Python Key Libraries" },
  // Azure Data Services (Level 4)
  { t: "Azure Data Lake Storage (ADLS)", d: "Scalable storage for big data analytics with hierarchical namespace.", l: 4, c: "Azure Data Services" },
  { t: "Gen1 / Gen2", d: "ADLS Gen1 (legacy) vs Gen2 (built on Blob with hierarchical namespace).", l: 4, c: "Azure Data Services" },
  { t: "Azure SQL Database", d: "Managed relational database service in Azure.", l: 4, c: "Azure Data Services" },
  { t: "Azure Cosmos DB", d: "Globally distributed multi-model database (NoSQL).", l: 4, c: "Azure Data Services" },
  { t: "Azure Table Storage", d: "NoSQL key-value store for semi-structured data.", l: 4, c: "Azure Data Services" },
  { t: "Azure Queue Storage", d: "Message queue service for async communication.", l: 4, c: "Azure Data Services" },
  { t: "Azure Database for PostgreSQL", d: "Managed PostgreSQL in Azure.", l: 4, c: "Azure Data Services" },
  { t: "Azure Database for MySQL", d: "Managed MySQL in Azure.", l: 4, c: "Azure Data Services" },
  { t: "Azure Cache for Redis", d: "Managed Redis in-memory cache.", l: 4, c: "Azure Data Services" },
  { t: "Azure Synapse Analytics", d: "Unified analytics service (SQL, Spark, pipelines).", l: 4, c: "Azure Data Services" },
  { t: "Synapse Studio", d: "Web experience for developing and operating in Synapse.", l: 4, c: "Azure Data Services" },
  { t: "Synapse Workspace", d: "Container for Synapse resources (SQL pools, Spark, pipelines).", l: 4, c: "Azure Data Services" },
  { t: "Dedicated SQL Pool", d: "Provisioned data warehouse in Synapse (formerly SQL DW).", l: 4, c: "Azure Data Services" },
  { t: "Serverless SQL Pool", d: "On-demand SQL over data lake in Synapse; no infrastructure.", l: 4, c: "Azure Data Services" },
  { t: "Apache Spark Pool", d: "Spark cluster in Synapse for big data processing.", l: 4, c: "Azure Data Services" },
  { t: "Azure Event Hubs", d: "Big data streaming platform and event ingestion.", l: 4, c: "Azure Data Services" },
  { t: "Azure Service Bus", d: "Message broker for decoupling applications (queues, topics).", l: 4, c: "Azure Data Services" },
  { t: "Azure Stream Analytics", d: "Real-time analytics on streaming data.", l: 4, c: "Azure Data Services" },
  { t: "Azure Logic Apps", d: "Workflow automation and integration (low-code).", l: 4, c: "Azure Data Services" },
  { t: "Azure Functions", d: "Serverless compute (event-driven, small code units).", l: 4, c: "Azure Data Services" },
  { t: "Azure API Management", d: "Gateway for publishing, securing, and managing APIs.", l: 4, c: "Azure Data Services" },
  { t: "Azure Key Vault", d: "Service for storing and managing secrets, keys, certificates.", l: 4, c: "Azure Data Services" },
  { t: "Secret", d: "Sensitive value (e.g. password, connection string) stored in Key Vault.", l: 4, c: "Azure Data Services" },
  { t: "Certificate", d: "Digital certificate for authentication or encryption.", l: 4, c: "Azure Data Services" },
  { t: "Token", d: "Credential (e.g. JWT) used for authentication/authorization.", l: 4, c: "Azure Data Services" },
  { t: "Azure Application Insights", d: "APM and monitoring for applications.", l: 4, c: "Azure Data Services" },
  // ETL & Data Integration (Level 4)
  { t: "ETL (Extract, Transform, Load)", d: "Process: extract from source, transform, load into target.", l: 4, c: "ETL & Data Integration" },
  { t: "ELT (Extract, Load, Transform)", d: "Load raw data first, then transform in the target system.", l: 4, c: "ETL & Data Integration" },
  { t: "Azure Data Factory (ADF)", d: "Cloud ETL/ELT service for data movement and transformation.", l: 4, c: "ETL & Data Integration" },
  { t: "Pipeline", d: "In ADF, a logical grouping of activities that perform a unit of work.", l: 4, c: "ETL & Data Integration" },
  { t: "Activity", d: "A step in an ADF pipeline (e.g. Copy, Data Flow).", l: 4, c: "ETL & Data Integration" },
  { t: "Trigger", d: "Mechanism that starts a pipeline (schedule, event, manual).", l: 4, c: "ETL & Data Integration" },
  { t: "Dataset", d: "Pointer to data in a store (structure and location).", l: 4, c: "ETL & Data Integration" },
  { t: "Linked Service", d: "Connection information to an external resource (e.g. storage, DB).", l: 4, c: "ETL & Data Integration" },
  { t: "Integration Runtime", d: "Compute used by ADF to run activities (Azure, self-hosted).", l: 4, c: "ETL & Data Integration" },
  { t: "Self-hosted Integration Runtime", d: "IR running on-prem or in VNet to access private data.", l: 4, c: "ETL & Data Integration" },
  { t: "Azure Integration Runtime", d: "Managed IR in Azure for cloud-to-cloud or public data.", l: 4, c: "ETL & Data Integration" },
  { t: "Copy Activity", d: "ADF activity that copies data between sources and sinks.", l: 4, c: "ETL & Data Integration" },
  { t: "Data Flow", d: "In ADF, visual transformation logic (mapping data flow).", l: 4, c: "ETL & Data Integration" },
  { t: "Mapping Data Flow", d: "Code-free transformation design in ADF (Spark under the hood).", l: 4, c: "ETL & Data Integration" },
  { t: "ForEach Activity", d: "ADF activity that iterates over a collection and runs inner activities.", l: 4, c: "ETL & Data Integration" },
  { t: "If Condition Activity", d: "ADF activity for conditional branching.", l: 4, c: "ETL & Data Integration" },
  { t: "Execute Pipeline Activity", d: "ADF activity that invokes another pipeline.", l: 4, c: "ETL & Data Integration" },
  { t: "Lookup Activity", d: "ADF activity that reads from a source and returns a value/dataset.", l: 4, c: "ETL & Data Integration" },
  { t: "Web Activity", d: "ADF activity that calls a REST endpoint.", l: 4, c: "ETL & Data Integration" },
  { t: "Wait Activity", d: "ADF activity that pauses the pipeline for a specified time.", l: 4, c: "ETL & Data Integration" },
  { t: "Stored Procedure Activity", d: "ADF activity that runs a stored procedure.", l: 4, c: "ETL & Data Integration" },
  { t: "Notebook Activity", d: "ADF activity that runs a Databricks or Synapse notebook.", l: 4, c: "ETL & Data Integration" },
  { t: "Get Metadata Activity", d: "ADF activity that retrieves metadata of data.", l: 4, c: "ETL & Data Integration" },
  { t: "Delete Activity", d: "ADF activity that deletes files or datasets.", l: 4, c: "ETL & Data Integration" },
  { t: "Dependency", d: "Relationship between activities (e.g. activity B runs after A).", l: 4, c: "ETL & Data Integration" },
  { t: "Parameter", d: "Named input to a pipeline or activity; can be set at run time.", l: 4, c: "ETL & Data Integration" },
  { t: "Variable", d: "Named value that can be set and read within a pipeline.", l: 4, c: "ETL & Data Integration" },
  { t: "Expression", d: "Formula or expression used in ADF (e.g. @concat, @pipeline().TriggerTime).", l: 4, c: "ETL & Data Integration" },
  { t: "Dynamic Content", d: "Content that is evaluated at runtime (expressions).", l: 4, c: "ETL & Data Integration" },
  { t: "Debug Mode", d: "Running a pipeline in ADF without publishing for testing.", l: 4, c: "ETL & Data Integration" },
  { t: "Publish", d: "Deploying pipelines and linked services to the data factory.", l: 4, c: "ETL & Data Integration" },
  { t: "ARM Template", d: "Azure Resource Manager template (JSON) for infrastructure as code.", l: 4, c: "ETL & Data Integration" },
  { t: "Tumbling Window Trigger", d: "Trigger that runs at fixed intervals (non-overlapping windows).", l: 4, c: "ETL & Data Integration" },
  { t: "Schedule Trigger", d: "Trigger that runs on a calendar schedule (cron-like).", l: 4, c: "ETL & Data Integration" },
  { t: "Event-based Trigger", d: "Trigger that runs in response to an event (e.g. blob created).", l: 4, c: "ETL & Data Integration" },
  { t: "Watermark", d: "Value (e.g. last modified time) used to track incremental load progress.", l: 4, c: "ETL & Data Integration" },
  { t: "Incremental Load", d: "Loading only new or changed data since the last run.", l: 4, c: "ETL & Data Integration" },
  { t: "Full Load", d: "Loading all data from source to target (replace or append).", l: 4, c: "ETL & Data Integration" },
  { t: "Snapshot", d: "Point-in-time copy of data.", l: 4, c: "ETL & Data Integration" },
  { t: "Change Data Capture (CDC)", d: "Identifying and capturing only changed rows for sync.", l: 4, c: "ETL & Data Integration" },
  { t: "Upsert", d: "Insert new rows or update existing ones (merge).", l: 4, c: "ETL & Data Integration" },
  { t: "Idempotent", d: "Operation that produces the same result when applied multiple times.", l: 4, c: "ETL & Data Integration" },
  // Apache Spark Core (Level 5)
  { t: "Apache Spark", d: "Unified engine for large-scale data processing (batch and streaming).", l: 5, c: "Apache Spark Core" },
  { t: "PySpark", d: "Python API for Apache Spark.", l: 5, c: "Apache Spark Core" },
  { t: "RDD (Resilient Distributed Dataset)", d: "Immutable distributed collection of objects; low-level Spark abstraction.", l: 5, c: "Apache Spark Core" },
  { t: "DataFrame", d: "Distributed collection of rows with named columns (Spark SQL).", l: 5, c: "Apache Spark Core" },
  { t: "Dataset", d: "Strongly typed collection (Scala/Java); DataFrame is Dataset[Row].", l: 5, c: "Apache Spark Core" },
  { t: "SparkContext", d: "Entry point for low-level Spark functionality (RDDs).", l: 5, c: "Apache Spark Core" },
  { t: "SparkSession", d: "Entry point for DataFrame and SQL; wraps SparkContext.", l: 5, c: "Apache Spark Core" },
  { t: "Spark SQL", d: "Module for structured data processing with SQL and DataFrame API.", l: 5, c: "Apache Spark Core" },
  { t: "Transformation", d: "Operation that produces a new RDD/DataFrame (lazy).", l: 5, c: "Apache Spark Core" },
  { t: "Action", d: "Operation that returns a result and triggers execution.", l: 5, c: "Apache Spark Core" },
  { t: "Lazy Evaluation", d: "Computations are not run until an action is called.", l: 5, c: "Apache Spark Core" },
  { t: "Partition", d: "Chunk of data that can be processed on one executor.", l: 5, c: "Apache Spark Core" },
  { t: "Shuffle", d: "Redistribution of data across partitions (e.g. for joins, groupBy).", l: 5, c: "Apache Spark Core" },
  { t: "Cache", d: "Persist an RDD/DataFrame in memory for reuse.", l: 5, c: "Apache Spark Core" },
  { t: "Persist", d: "Store RDD/DataFrame with specified storage level (memory, disk).", l: 5, c: "Apache Spark Core" },
  { t: "Stage", d: "Set of tasks that can run together (before a shuffle boundary).", l: 5, c: "Apache Spark Core" },
  { t: "Task", d: "Unit of work sent to an executor (one partition).", l: 5, c: "Apache Spark Core" },
  { t: "Executor", d: "Process that runs tasks and stores data for a Spark application.", l: 5, c: "Apache Spark Core" },
  { t: "Driver", d: "Process that runs the main() and coordinates the application.", l: 5, c: "Apache Spark Core" },
  { t: "SparkUI", d: "Web UI for monitoring Spark jobs, stages, and tasks.", l: 5, c: "Apache Spark Core" },
  { t: "Catalyst Optimizer", d: "Spark's rule-based optimizer for logical and physical plans.", l: 5, c: "Apache Spark Core" },
  { t: "DAG (Directed Acyclic Graph)", d: "Graph of RDD dependencies and stages; used for scheduling.", l: 5, c: "Apache Spark Core" },
  { t: "UDF (User Defined Function)", d: "Custom function applied to DataFrame columns (row-by-row).", l: 5, c: "Apache Spark Core" },
  { t: "Pandas UDF (Vectorized UDF)", d: "UDF that operates on Arrow batches for better performance.", l: 5, c: "Apache Spark Core" },
  { t: "coalesce", d: "Reduce number of partitions without shuffle.", l: 5, c: "Apache Spark Core" },
  { t: "repartition", d: "Change number of partitions; triggers shuffle.", l: 5, c: "Apache Spark Core" },
  { t: "broadcast join", d: "Join where small table is sent to all executors to avoid shuffle.", l: 5, c: "Apache Spark Core" },
  { t: "shuffle join", d: "Join that requires redistributing data (e.g. sort-merge).", l: 5, c: "Apache Spark Core" },
  { t: "sort merge join", d: "Join algorithm that sorts and merges partitioned data.", l: 5, c: "Apache Spark Core" },
  { t: "Bucketing", d: "Pre-partitioning data by column values for efficient joins.", l: 5, c: "Apache Spark Core" },
  { t: "Predicate Pushdown", d: "Pushing filter down to the data source to reduce data read.", l: 5, c: "Apache Spark Core" },
  { t: "Column Pruning", d: "Reading only columns that are needed.", l: 5, c: "Apache Spark Core" },
  { t: "Adaptive Query Execution (AQE)", d: "Runtime optimization (e.g. coalesce partitions, switch join strategy).", l: 5, c: "Apache Spark Core" },
  { t: "Checkpoint", d: "Saving RDD/DataFrame to reliable storage to break lineage.", l: 5, c: "Apache Spark Core" },
  { t: "Broadcast Variable", d: "Read-only variable cached on each machine.", l: 5, c: "Apache Spark Core" },
  { t: "Accumulator", d: "Variable that workers can add to (e.g. counters).", l: 5, c: "Apache Spark Core" },
  // Spark Streaming (Level 5)
  { t: "Structured Streaming", d: "Spark's API for stream processing on DataFrames.", l: 5, c: "Spark Streaming" },
  { t: "readStream", d: "Method to create a streaming DataFrame from a source.", l: 5, c: "Spark Streaming" },
  { t: "writeStream", d: "Method to write a streaming query to a sink.", l: 5, c: "Spark Streaming" },
  { t: "Micro-batch", d: "Processing streams in small batches at trigger intervals.", l: 5, c: "Spark Streaming" },
  { t: "Watermark", d: "Threshold for how late data can be for stateful operations.", l: 5, c: "Spark Streaming" },
  { t: "Trigger", d: "Defines when to run a streaming query (e.g. interval, once).", l: 5, c: "Spark Streaming" },
  { t: "Streaming Checkpoint", d: "Location where progress and state are stored for recovery.", l: 5, c: "Spark Streaming" },
  // Delta Lake (Level 5)
  { t: "Delta Lake", d: "Storage layer that adds ACID and time travel to data lakes.", l: 5, c: "Delta Lake" },
  { t: "Delta Table", d: "Table stored in Delta format with transaction log.", l: 5, c: "Delta Lake" },
  { t: "ACID Transactions", d: "Atomicity, Consistency, Isolation, Durability for data operations.", l: 5, c: "Delta Lake" },
  { t: "Time Travel", d: "Ability to query or restore to a previous version of a Delta table.", l: 5, c: "Delta Lake" },
  { t: "Merge (UPSERT)", d: "Insert or update rows based on a match condition.", l: 5, c: "Delta Lake" },
  { t: "Schema Evolution", d: "Changing schema over time (e.g. add column) in Delta.", l: 5, c: "Delta Lake" },
  { t: "Schema Enforcement", d: "Rejecting writes that don't match the table schema.", l: 5, c: "Delta Lake" },
  { t: "Auto Loader", d: "Databricks capability for incremental file ingestion.", l: 5, c: "Delta Lake" },
  { t: "CloudFiles", d: "Databricks utility for multi-cloud file ingestion with schema inference.", l: 5, c: "Delta Lake" },
  // Azure Databricks (Level 5)
  { t: "Azure Databricks", d: "Apache Spark-based analytics platform on Azure.", l: 5, c: "Azure Databricks" },
  { t: "Cluster", d: "Set of nodes that run Spark jobs in Databricks.", l: 5, c: "Azure Databricks" },
  { t: "Worker Node", d: "Node that runs tasks and stores data in a Spark cluster.", l: 5, c: "Azure Databricks" },
  { t: "Driver Node", d: "Node that runs the Spark driver (coordinates the application).", l: 5, c: "Azure Databricks" },
  { t: "Job", d: "Scheduled or triggered run of a notebook or JAR in Databricks.", l: 5, c: "Azure Databricks" },
  { t: "Notebook", d: "Interactive document with code and markdown (Databricks, Synapse).", l: 5, c: "Azure Databricks" },
  { t: "Interactive Cluster", d: "Long-running cluster for ad-hoc queries and notebooks.", l: 5, c: "Azure Databricks" },
  { t: "Job Cluster", d: "Cluster created for a job and terminated when the job ends.", l: 5, c: "Azure Databricks" },
  { t: "Workflow", d: "Orchestration of multiple tasks (jobs) in Databricks.", l: 5, c: "Azure Databricks" },
  { t: "DLT (Delta Live Tables)", d: "Databricks framework for building reliable streaming/batch pipelines.", l: 5, c: "Azure Databricks" },
  { t: "DBFS (Databricks File System)", d: "Distributed file system abstraction in Databricks.", l: 5, c: "Azure Databricks" },
  { t: "Mount Point", d: "Reference to external storage (e.g. ADLS) in Databricks.", l: 5, c: "Azure Databricks" },
  { t: "Databricks Unity Catalog", d: "Unified governance layer for data assets across Databricks.", l: 5, c: "Azure Databricks" },
  { t: "Metastore", d: "Catalog that stores metadata (schemas, tables) for Spark/Databricks.", l: 5, c: "Azure Databricks" },
  { t: "Catalog", d: "Top-level container for schemas and tables in Unity Catalog.", l: 5, c: "Azure Databricks" },
  { t: "Medallion Architecture", d: "Bronze (raw), Silver (cleaned), Gold (business-level) layers.", l: 5, c: "Azure Databricks" },
  { t: "Bronze Layer", d: "Raw data ingested with minimal transformation.", l: 5, c: "Azure Databricks" },
  { t: "Silver Layer", d: "Cleaned, validated, and conformed data.", l: 5, c: "Azure Databricks" },
  { t: "Gold Layer", d: "Business-level aggregates and metrics for reporting.", l: 5, c: "Azure Databricks" },
  // Data Architecture Concepts (Level 5)
  { t: "Data Warehouse", d: "Central repository of integrated data for analytics.", l: 5, c: "Data Architecture Concepts" },
  { t: "Data Lake", d: "Storage that holds raw data in native format until needed.", l: 5, c: "Data Architecture Concepts" },
  { t: "Data Lakehouse", d: "Architecture combining lake flexibility with warehouse structure (e.g. Delta).", l: 5, c: "Data Architecture Concepts" },
  { t: "Data Mart", d: "Subset of a data warehouse focused on a specific subject or team.", l: 5, c: "Data Architecture Concepts" },
  { t: "Data Mesh", d: "Decentralized ownership of data as a product.", l: 5, c: "Data Architecture Concepts" },
  { t: "Star Schema", d: "Fact table surrounded by dimension tables; denormalized for analytics.", l: 5, c: "Data Architecture Concepts" },
  { t: "Snowflake Schema", d: "Normalized dimension tables (dimensions have sub-dimensions).", l: 5, c: "Data Architecture Concepts" },
  { t: "Fact Table", d: "Table of measurable events (e.g. sales) with foreign keys to dimensions.", l: 5, c: "Data Architecture Concepts" },
  { t: "Dimension Table", d: "Table of descriptive attributes (e.g. product, customer, time).", l: 5, c: "Data Architecture Concepts" },
  { t: "Slowly Changing Dimension (SCD)", d: "Dimension that changes over time; Type 1/2/3 strategies.", l: 5, c: "Data Architecture Concepts" },
  { t: "Surrogate Key", d: "System-generated key (e.g. identity) used in the warehouse.", l: 5, c: "Data Architecture Concepts" },
  { t: "Natural Key", d: "Business key from the source system.", l: 5, c: "Data Architecture Concepts" },
  { t: "Normalization", d: "Design that reduces redundancy and dependency.", l: 5, c: "Data Architecture Concepts" },
  { t: "Denormalization", d: "Adding redundant data to improve read performance.", l: 5, c: "Data Architecture Concepts" },
  { t: "ERD (Entity Relationship Diagram)", d: "Diagram showing entities and relationships.", l: 5, c: "Data Architecture Concepts" },
  { t: "Cardinality", d: "Relationship type: one-to-one, one-to-many, many-to-many.", l: 5, c: "Data Architecture Concepts" },
  { t: "OLTP (Online Transaction Processing)", d: "Systems optimized for transactional workloads.", l: 5, c: "Data Architecture Concepts" },
  { t: "OLAP (Online Analytical Processing)", d: "Systems optimized for analytical queries.", l: 5, c: "Data Architecture Concepts" },
  // SQL Advanced (Level 5)
  { t: "CTE (Common Table Expression)", d: "Named temporary result set defined with WITH.", l: 5, c: "SQL Advanced" },
  { t: "WITH clause", d: "Defines CTEs before the main query.", l: 5, c: "SQL Advanced" },
  { t: "Subquery", d: "Query nested inside another query.", l: 5, c: "SQL Advanced" },
  { t: "Window Function", d: "Function that operates on a set of rows related to the current row.", l: 5, c: "SQL Advanced" },
  { t: "OVER clause", d: "Defines the window (partition, order) for window functions.", l: 5, c: "SQL Advanced" },
  { t: "PARTITION BY", d: "Divides the result set into partitions for window functions.", l: 5, c: "SQL Advanced" },
  { t: "ROW_NUMBER", d: "Window function that assigns a unique number to each row in a partition.", l: 5, c: "SQL Advanced" },
  { t: "RANK", d: "Window function that ranks rows with gaps for ties.", l: 5, c: "SQL Advanced" },
  { t: "DENSE_RANK", d: "Window function that ranks rows without gaps for ties.", l: 5, c: "SQL Advanced" },
  { t: "LEAD", d: "Window function that accesses a row at a following offset.", l: 5, c: "SQL Advanced" },
  { t: "LAG", d: "Window function that accesses a row at a previous offset.", l: 5, c: "SQL Advanced" },
  { t: "COALESCE", d: "Returns the first non-NULL expression.", l: 5, c: "SQL Advanced" },
  { t: "CASE WHEN", d: "Conditional expression for branching in SQL.", l: 5, c: "SQL Advanced" },
  { t: "PIVOT", d: "Transforms rows into columns (rotate).", l: 5, c: "SQL Advanced" },
  { t: "UNPIVOT", d: "Transforms columns into rows.", l: 5, c: "SQL Advanced" },
  { t: "MERGE Statement", d: "Upsert: insert, update, or delete based on match.", l: 5, c: "SQL Advanced" },
  { t: "Execution Plan", d: "Query optimizer's chosen plan (operators, order).", l: 5, c: "SQL Advanced" },
  { t: "Clustered Index", d: "Index that determines physical order of rows (e.g. SQL Server).", l: 5, c: "SQL Advanced" },
  { t: "Non-Clustered Index", d: "Index that points to rows; table can have one clustered, many non-clustered.", l: 5, c: "SQL Advanced" },
  { t: "Transaction", d: "Unit of work that is committed or rolled back as a whole.", l: 5, c: "SQL Advanced" },
  { t: "COMMIT", d: "Makes transaction changes permanent.", l: 5, c: "SQL Advanced" },
  { t: "ROLLBACK", d: "Reverts transaction changes.", l: 5, c: "SQL Advanced" },
  // Streaming & Messaging (Level 5)
  { t: "Apache Kafka", d: "Distributed event streaming platform (topics, producers, consumers).", l: 5, c: "Streaming & Messaging" },
  { t: "Kafka Topic", d: "Category/feed name to which records are published.", l: 5, c: "Streaming & Messaging" },
  { t: "Producer", d: "Client that publishes records to a topic.", l: 5, c: "Streaming & Messaging" },
  { t: "Consumer", d: "Client that subscribes to topics and processes records.", l: 5, c: "Streaming & Messaging" },
  { t: "Consumer Group", d: "Set of consumers that share workload for a set of partitions.", l: 5, c: "Streaming & Messaging" },
  { t: "Partition", d: "In Kafka, ordered, immutable sequence of records in a topic.", l: 5, c: "Streaming & Messaging" },
  { t: "Offset", d: "Position of a consumer in a partition.", l: 5, c: "Streaming & Messaging" },
  { t: "Message", d: "Unit of data sent or received in a messaging system.", l: 5, c: "Streaming & Messaging" },
  { t: "Queue", d: "FIFO structure for messages; one consumer per message typically.", l: 5, c: "Streaming & Messaging" },
  { t: "Publish / Subscribe (Pub/Sub)", d: "Pattern where publishers send to topics and subscribers receive.", l: 5, c: "Streaming & Messaging" },
  { t: "Dead Letter Queue", d: "Queue for messages that failed processing.", l: 5, c: "Streaming & Messaging" },
  { t: "WebSocket", d: "Protocol for full-duplex communication over a single connection.", l: 5, c: "Streaming & Messaging" },
  // dbt & Orchestration (Level 5)
  { t: "dbt Core", d: "Open-source CLI for transforming data in the warehouse with SQL.", l: 5, c: "dbt & Orchestration" },
  { t: "dbt Model", d: "SQL select that builds a table or view in the warehouse.", l: 5, c: "dbt & Orchestration" },
  { t: "dbt Test", d: "Assertions on data quality (e.g. uniqueness, not null).", l: 5, c: "dbt & Orchestration" },
  { t: "dbt Ref", d: "Reference to another model for dependencies.", l: 5, c: "dbt & Orchestration" },
  { t: "Apache Airflow", d: "Platform to programmatically author, schedule, and monitor workflows.", l: 5, c: "dbt & Orchestration" },
  { t: "DAG (Directed Acyclic Graph)", d: "In Airflow, a set of tasks with dependencies (no cycles).", l: 5, c: "dbt & Orchestration" },
  { t: "Operator", d: "In Airflow, a template for a single task (e.g. PythonOperator).", l: 5, c: "dbt & Orchestration" },
  { t: "Task", d: "Instance of an operator; a node in a DAG.", l: 5, c: "dbt & Orchestration" },
  { t: "XCom", d: "Mechanism for tasks to pass small data in Airflow.", l: 5, c: "dbt & Orchestration" },
  { t: "Hook", d: "Interface to external systems (e.g. database, API) in Airflow.", l: 5, c: "dbt & Orchestration" },
  // Data Quality & Governance (Level 5)
  { t: "Data Quality", d: "Fitness of data for its intended use (accuracy, completeness, etc.).", l: 5, c: "Data Quality & Governance" },
  { t: "Data Lineage", d: "Tracking where data comes from and how it is transformed.", l: 5, c: "Data Quality & Governance" },
  { t: "Data Catalog", d: "Inventory of data assets with metadata and search.", l: 5, c: "Data Quality & Governance" },
  { t: "Data Governance", d: "Framework for managing availability, usability, and security of data.", l: 5, c: "Data Quality & Governance" },
  { t: "Metadata", d: "Data that describes other data (schema, lineage, usage).", l: 5, c: "Data Quality & Governance" },
  { t: "PII (Personally Identifiable Information)", d: "Data that can identify an individual; requires protection.", l: 5, c: "Data Quality & Governance" },
  { t: "Microsoft Purview (Azure Purview)", d: "Unified data governance and catalog service.", l: 5, c: "Data Quality & Governance" },
  // Security & Access (Level 5)
  { t: "Role-Based Access Control (RBAC)", d: "Access control based on roles assigned to users.", l: 5, c: "Security & Access" },
  { t: "Service Principal", d: "Identity for an app or service to authenticate to Azure.", l: 5, c: "Security & Access" },
  { t: "Managed Identity", d: "Azure identity for resources; no credentials to manage.", l: 5, c: "Security & Access" },
  { t: "OAuth", d: "Protocol for delegated authorization (e.g. access tokens).", l: 5, c: "Security & Access" },
  { t: "Authentication", d: "Verifying identity (who you are).", l: 5, c: "Security & Access" },
  { t: "Authorization", d: "Verifying permissions (what you can do).", l: 5, c: "Security & Access" },
  { t: "Encryption", d: "Encoding data so only authorized parties can read it.", l: 5, c: "Security & Access" },
  { t: "Private Endpoint", d: "Network interface that connects to a service over private link.", l: 5, c: "Security & Access" },
  // DevOps & Version Control (Level 5)
  { t: "CI/CD", d: "Continuous Integration and Continuous Deployment/Delivery.", l: 5, c: "DevOps & Version Control" },
  { t: "Git", d: "Distributed version control system.", l: 5, c: "DevOps & Version Control" },
  { t: "Repository (Repo)", d: "Storage for code and its version history.", l: 5, c: "DevOps & Version Control" },
  { t: "Branch", d: "Divergent line of development from the main codebase.", l: 5, c: "DevOps & Version Control" },
  { t: "Pull Request", d: "Proposal to merge changes from one branch into another.", l: 5, c: "DevOps & Version Control" },
  { t: "Docker", d: "Platform for building and running containers.", l: 5, c: "DevOps & Version Control" },
  { t: "Container", d: "Lightweight, runnable instance of an image.", l: 5, c: "DevOps & Version Control" },
  { t: "Infrastructure as Code (IaC)", d: "Managing infrastructure via code (e.g. ARM, Terraform).", l: 5, c: "DevOps & Version Control" },
  { t: "Terraform", d: "Tool for defining and provisioning infrastructure as code.", l: 5, c: "DevOps & Version Control" },
  // Monitoring & Observability (Level 5)
  { t: "Logging", d: "Recording events and messages for debugging and audit.", l: 5, c: "Monitoring & Observability" },
  { t: "Tracing", d: "Tracking requests across services (distributed tracing).", l: 5, c: "Monitoring & Observability" },
  { t: "Metrics", d: "Numeric measurements (e.g. latency, throughput, errors).", l: 5, c: "Monitoring & Observability" },
  { t: "Observability", d: "Ability to infer internal state from external outputs (logs, metrics, traces).", l: 5, c: "Monitoring & Observability" },
  { t: "SLA (Service Level Agreement)", d: "Commitment to a level of service (e.g. uptime).", l: 5, c: "Monitoring & Observability" },
  // Networking & Protocols (Level 5)
  { t: "REST API", d: "API that uses HTTP methods and stateless requests.", l: 5, c: "Networking & Protocols" },
  { t: "OpenAPI / Swagger", d: "Specification for describing REST APIs.", l: 5, c: "Networking & Protocols" },
  { t: "Load Balancer", d: "Distributes traffic across multiple servers.", l: 5, c: "Networking & Protocols" },
  { t: "Azure VNet", d: "Virtual network in Azure for private connectivity.", l: 5, c: "Networking & Protocols" },
  // Power BI & Reporting (Level 5)
  { t: "Power BI", d: "Microsoft's business analytics service for reports and dashboards.", l: 5, c: "Power BI & Reporting" },
  { t: "Report", d: "Interactive page(s) with visuals and filters.", l: 5, c: "Power BI & Reporting" },
  { t: "Dashboard", d: "Single-page view of key metrics and visuals.", l: 5, c: "Power BI & Reporting" },
  { t: "Measure", d: "Calculated formula (e.g. DAX) for aggregations in Power BI.", l: 5, c: "Power BI & Reporting" },
  { t: "KPI (Key Performance Indicator)", d: "Metric used to evaluate success (e.g. target vs actual).", l: 5, c: "Power BI & Reporting" },
];
